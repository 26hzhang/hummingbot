"""
# OS Spread Z-Score å¯è§†åŒ–åˆ†æ - çº¯1åˆ†é’Ÿæ•°æ®ç‰ˆæœ¬

åŸºäºç°æœ‰ pair_selection_analysis.py é€»è¾‘ï¼Œä½¿ç”¨**çº¯1åˆ†é’Ÿæ•°æ®**å¯è§†åŒ–ç»™å®šä»·æ ¼å¯¹çš„ OS spread z-score å˜åŒ–ã€‚

**ä¸åŒæ—¶é—´çª—å£ç‰ˆæœ¬çš„åŒºåˆ«**:
- **å•ä¸€æ•°æ®æº**: ä»…ä½¿ç”¨1åˆ†é’ŸKçº¿æ•°æ®
- **ç»Ÿä¸€æ—¶é—´ç²’åº¦**: ISå’ŒOSé˜¶æ®µéƒ½ä½¿ç”¨ç›¸åŒçš„1åˆ†é’Ÿé—´éš”
- **æ¶æ„**: æ— éœ€å¤„ç†æ—¶é—´å¯¹é½å’Œæ•°æ®è½¬æ¢é—®é¢˜
- **ç›´æ¥å¯¹åº”**: æ›´æ¥è¿‘stat_arbæ§åˆ¶å™¨å®é™…ä½¿ç”¨çš„æ•°æ®ç»“æ„
"""
# ç¦ç”¨æ‰€æœ‰matplotlibå­—ä½“è­¦å‘Š
import logging
import warnings
from pathlib import Path

import matplotlib
import matplotlib.pyplot as plt
import mplfinance as mpf
import numpy as np
import pandas as pd
from sklearn.linear_model import HuberRegressor, LinearRegression
from statsmodels.tsa.stattools import adfuller

logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)

# ç®€å•è®¾ç½®å­—ä½“ï¼Œé¿å…è­¦å‘Š
matplotlib.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')


class DataLoader:

    def __init__(self, data_dir="/Users/zhanghao/GitHub/hummingbot/data/futures_1m"):
        self.data_dir = Path(data_dir)
        self.pairs = [f.stem.replace("_1m", "") for f in self.data_dir.glob("*_1m.csv")]
        # print(f"Found {len(self.pairs)} pairs (1m data)")
        # print(f"Available pairs: {', '.join(self.pairs[:10])}{'...' if len(self.pairs) > 10 else ''}")

    def load_pair_data(self, coin1, coin2, start_date=None, end_date=None, silent=False):
        pair1 = f"{coin1}USDT"
        pair2 = f"{coin2}USDT"

        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        file1 = self.data_dir / f"{pair1}_1m.csv"
        file2 = self.data_dir / f"{pair2}_1m.csv"

        missing_files = []
        if not file1.exists():
            missing_files.append(f"{pair1}_1m.csv")
        if not file2.exists():
            missing_files.append(f"{pair2}_1m.csv")

        if missing_files:
            if not silent:
                print(f"Files not found: {missing_files}")
            return None

        try:
            # åŠ è½½æ•°æ®
            df1 = pd.read_csv(file1)
            df2 = pd.read_csv(file2)

            # è½¬æ¢æ—¶é—´æˆ³
            df1['timestamp'] = pd.to_datetime(df1['open_time'], utc=True)
            df2['timestamp'] = pd.to_datetime(df2['open_time'], utc=True)

            # è®¡ç®—å…±åŒæ—¶é—´èŒƒå›´
            common_start = max(df1['timestamp'].min(), df2['timestamp'].min())
            common_end = min(df1['timestamp'].max(), df2['timestamp'].max())

            # ç”¨æˆ·æŒ‡å®šæ—¥æœŸèŒƒå›´
            if start_date:
                start_date_tz = pd.to_datetime(start_date, utc=True)
                common_start = max(common_start, start_date_tz)
            if end_date:
                end_date_tz = pd.to_datetime(end_date, utc=True)
                common_end = min(common_end, end_date_tz)

            # è¿‡æ»¤åˆ°å…±åŒæ—¶é—´èŒƒå›´å¹¶æ’åº
            df1_filtered = df1[(df1['timestamp'] >= common_start) & (df1['timestamp'] <= common_end)].sort_values('timestamp').reset_index(drop=True)
            df2_filtered = df2[(df2['timestamp'] >= common_start) & (df2['timestamp'] <= common_end)].sort_values('timestamp').reset_index(drop=True)

            # æ„å»ºå¯¹é½æ•°æ®
            df1_clean = df1_filtered[['timestamp', 'open', 'high', 'low', 'close', 'volume']].rename(columns={
                'open': f'{coin1}_open', 'high': f'{coin1}_high', 'low': f'{coin1}_low',
                'close': f'{coin1}_close', 'volume': f'{coin1}_volume'
            })
            df2_clean = df2_filtered[['timestamp', 'open', 'high', 'low', 'close', 'volume']].rename(columns={
                'open': f'{coin2}_open', 'high': f'{coin2}_high', 'low': f'{coin2}_low',
                'close': f'{coin2}_close', 'volume': f'{coin2}_volume'
            })

            # å†…è¿æ¥å¾—åˆ°å¯¹é½çš„æ•°æ®
            data = pd.merge(df1_clean, df2_clean, on='timestamp', how='inner').sort_values('timestamp').reset_index(drop=True)

            if not silent:
                print(f"1mæ•°æ®åŠ è½½å®Œæˆ {coin1}-{coin2}")
                print(f"æ•°æ®é‡: {len(data)} æ¡")
                print(f"æ—¶é—´èŒƒå›´: {common_start} è‡³ {common_end}")
                print(f"æ—¶é—´è·¨åº¦: {(common_end - common_start).days} å¤©")

            return data

        except Exception as e:
            if not silent:
                print(f"æ•°æ®åŠ è½½é”™è¯¯: {str(e)}")
            return None


class RollingWindowAnalyzer:
    """æ»‘åŠ¨çª—å£åˆ†æå™¨ - ç›´æ¥çš„ç»Ÿè®¡å¥—åˆ©åˆ†æ"""

    def __init__(
        self, window_size=2000, step_size=500, lookback_zscore=1000, ma_window=None, ma_type='sma', reg_method=None):
        """
        å‚æ•°:
        window_size: OLSæ‹Ÿåˆçš„æ»‘åŠ¨çª—å£å¤§å°ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰
        step_size: æ¯æ¬¡å‰è¿›çš„æ­¥é•¿ï¼ˆæ•°æ®ç‚¹æ•°ï¼‰
        lookback_zscore: è®¡ç®—z-scoreåŸºå‡†æ—¶ä½¿ç”¨çš„å†å²spreadæ•°é‡
        ma_window: int, MAå¹³æ»‘çª—å£å¤§å°ï¼ŒNoneè¡¨ç¤ºä¸å¯ç”¨OLSå¹³æ»‘
        ma_type: str, MAç±»å‹ ('sma'=ç®€å•ç§»åŠ¨å¹³å‡, 'ema'=æŒ‡æ•°ç§»åŠ¨å¹³å‡)
        reg_method: str, å›å½’æ–¹æ³• (None='æ™®é€šOLS', 'huber'='Huberå›å½’')
        """
        self.window_size = window_size
        self.step_size = step_size
        self.lookback_zscore = lookback_zscore
        self.ma_window = ma_window
        self.ma_type = ma_type
        self.reg_method = reg_method if reg_method is not None else 'ols'

        # å­˜å‚¨åˆ†æç»“æœ
        self.analysis_results = None
        self.data = None
        self.coin1 = None
        self.coin2 = None

    def analyze_pair(self, data, coin1, coin2, price_transform='log'):
        """æ»‘åŠ¨çª—å£åˆ†æ - ç›´æ¥è®¡ç®—å½“å‰z-score"""

        # å­˜å‚¨æ•°æ®ç”¨äºåç»­åˆ†æ
        self.data = data
        self.coin1 = coin1
        self.coin2 = coin2

        # éªŒè¯æ•°æ®é•¿åº¦
        min_required = self.window_size + self.lookback_zscore + self.step_size
        if len(data) < min_required:
            print(f"æ•°æ®ä¸è¶³: éœ€è¦è‡³å°‘{min_required}æ¡æ•°æ®")
            print(f"å®é™…: {len(data)}æ¡")
            return None

        # æå–ä»·æ ¼æ•°æ®
        if price_transform == 'log':
            price1 = np.log(data[f'{coin1}_close'])
            price2 = np.log(data[f'{coin2}_close'])
        elif price_transform in ['raw', 'ratio']:
            price1 = data[f'{coin1}_close']
            price2 = data[f'{coin2}_close']
        else:
            raise ValueError(f"Unsupported price_transform: {price_transform}")

        # å­˜å‚¨ç»“æœ
        results = []
        historical_spreads = []  # ä¸¥æ ¼çš„å†å²spreadè®°å½•

        print(f"æ»‘åŠ¨çª—å£åˆ†æ {coin1}-{coin2}")
        print(f"çª—å£å¤§å°: {self.window_size}, æ­¥é•¿: {self.step_size}, Z-Scoreå›çœ‹: {self.lookback_zscore}")
        if price_transform == 'ratio':
            print(f"ğŸ’¹ ä»·æ ¼å˜æ¢: {price_transform.upper()} æ–¹å¼ (åŸºäºçª—å£ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹)")
        else:
            print(f"ğŸ’¹ ä»·æ ¼å˜æ¢: {price_transform.upper()} æ–¹å¼")
        if self.ma_window is not None:
            print(f"ğŸ”§ OLSå‚æ•°å¹³æ»‘: {self.ma_type.upper()} çª—å£={self.ma_window}")
        if self.reg_method is not None:
            print(f"ğŸ›¡ï¸ é²æ£’å›å½’: {self.reg_method.upper()} æ–¹æ³•")
        print("âœ… é€»è¾‘: åŸºäºå†å²æ•°æ®ç›´æ¥è®¡ç®—å½“å‰z-score")

        # æ»‘åŠ¨çª—å£åˆ†æ
        for i in range(self.window_size, len(data), self.step_size):
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰è¶³å¤Ÿçš„æ•°æ®
            if i + self.step_size > len(data):
                break

            # 1. æå–çª—å£æ•°æ®è¿›è¡ŒOLSæ‹Ÿåˆï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
            window_start = i - self.window_size
            window_end = i
            window_p1 = price1.iloc[window_start:window_end]
            window_p2 = price2.iloc[window_start:window_end]

            # å¦‚æœæ˜¯ratioæ¨¡å¼ï¼ŒåŸºäºçª—å£ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹è®¡ç®—æ¯”ç‡
            if price_transform == 'ratio':
                base_price1 = window_p1.iloc[0]
                base_price2 = window_p2.iloc[0]
                window_p1 = window_p1 / base_price1
                window_p2 = window_p2 / base_price2

            # OLSæ‹Ÿåˆ
            cointegration = self._fit_algo(window_p1, window_p2)
            if cointegration is None:
                continue

            # 2. åŸºäºå†å²spreadå»ºç«‹z-scoreåŸºå‡†
            if len(historical_spreads) >= self.lookback_zscore:
                zscore_baseline_spreads = historical_spreads[-self.lookback_zscore:-1]
            else:
                zscore_baseline_spreads = historical_spreads.copy()

            # è®¡ç®—å†å²åŸºå‡†ç»Ÿè®¡é‡
            if len(zscore_baseline_spreads) > 0:
                baseline_mean = np.mean(zscore_baseline_spreads)
                baseline_std = np.std(zscore_baseline_spreads)
                if baseline_std == 0:
                    baseline_std = 1.0  # é¿å…é™¤é›¶
            else:
                baseline_mean = 0.0
                baseline_std = 1.0

            # 3. é€ç‚¹å¤„ç†ä¸‹ä¸€ä¸ªstep_sizeåŒºé—´
            for j in range(self.step_size):
                current_position = i + j
                if current_position >= len(data):
                    break

                # è·å–å½“å‰æ—¶ç‚¹çš„ä»·æ ¼
                current_p1 = price1.iloc[current_position]
                current_p2 = price2.iloc[current_position]
                current_timestamp = data['timestamp'].iloc[current_position]

                # 4. è®¡ç®—å½“å‰spreadå’Œz-score
                # åŸºäºOLSå‚æ•°è®¡ç®—å½“å‰spread
                current_spread = current_p2 - cointegration['alpha'] - cointegration['beta'] * current_p1

                # åŸºäºå†å²åŸºå‡†è®¡ç®—å½“å‰z-score
                current_zscore = (current_spread - baseline_mean) / baseline_std

                # 5. å­˜å‚¨å½“å‰ç‚¹çš„ç»“æœ
                results.append({
                    'timestamp': current_timestamp,
                    'window_start_idx': window_start,
                    'window_end_idx': window_end,
                    'position': current_position,
                    'alpha': cointegration['alpha'],
                    'beta': cointegration['beta'],
                    'r_squared': cointegration['r_squared'],
                    'adf_pvalue': cointegration['pvalue'],
                    'current_spread': current_spread,
                    'current_zscore': current_zscore,
                    'baseline_mean': baseline_mean,
                    'baseline_std': baseline_std,
                    'lookback_count': len(zscore_baseline_spreads)
                })

                # 6. **å…³é”®**: å°†å½“å‰spreadåŠ å…¥å†å²è®°å½•ï¼ˆé˜²æ•°æ®æ³„éœ²ï¼‰
                historical_spreads.append(current_spread)

        if len(results) == 0:
            print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æç»“æœ")
            return None

        # æ•´ç†åˆ†æç»“æœ
        self.analysis_results = {
            'results': results,
            'timestamps': [r['timestamp'] for r in results],
            'current_spreads': [r['current_spread'] for r in results],
            'current_zscores': [r['current_zscore'] for r in results],
            'alphas': [r['alpha'] for r in results],
            'betas': [r['beta'] for r in results],
            'r_squared_values': [r['r_squared'] for r in results],
            'adf_pvalues': [r['adf_pvalue'] for r in results]
        }

        print(f"æˆåŠŸåˆ†æ{len(results)}ä¸ªæ•°æ®ç‚¹")
        print(f"å½“å‰z-score: âœ… åŸºäºå†å²ç»Ÿè®¡è®¡ç®—å½“å‰spreadçš„å¼‚å¸¸ç¨‹åº¦")

        # ç”Ÿæˆå¯è§†åŒ–
        # self._plot_analysis()

        # æ‰“å°ç»Ÿè®¡æ‘˜è¦
        self._print_summary()

        return self.analysis_results

    def _fit_algo(self, p1, p2):
        """æ‹Ÿåˆåæ•´å…³ç³» - å†…éƒ¨è¿›è¡Œä»·æ ¼å¹³æ»‘"""
        try:
            # ä»…åœ¨OLSè®¡ç®—æ—¶è¿›è¡Œä»·æ ¼å¹³æ»‘
            if self.ma_window is not None and self.ma_window > 1:
                if self.ma_type == 'sma':
                    p1_for_fit = p1.rolling(window=self.ma_window, min_periods=1).mean()
                    p2_for_fit = p2.rolling(window=self.ma_window, min_periods=1).mean()
                elif self.ma_type == 'ema':
                    p1_for_fit = p1.ewm(span=self.ma_window).mean()
                    p2_for_fit = p2.ewm(span=self.ma_window).mean()
                else:
                    p1_for_fit = p1
                    p2_for_fit = p2
            else:
                p1_for_fit = p1
                p2_for_fit = p2

            # ä½¿ç”¨å¹³æ»‘åçš„ä»·æ ¼è¿›è¡Œçº¿æ€§å›å½’
            X = p1_for_fit.values.reshape(-1, 1)
            y = p2_for_fit.values

            # æ ¹æ®robust_methodé€‰æ‹©å›å½’å™¨
            if self.reg_method == 'huber':
                reg = HuberRegressor(epsilon=1.5).fit(X, y)
            else:
                # é»˜è®¤ä½¿ç”¨æ™®é€šOLS
                reg = LinearRegression().fit(X, y)

            alpha = reg.intercept_
            beta = reg.coef_[0]

            # è®¡ç®—R-squaredï¼ˆä½¿ç”¨å¹³æ»‘ä»·æ ¼ï¼‰
            y_pred = reg.predict(X)
            ss_res = np.sum((y - y_pred) ** 2)
            ss_tot = np.sum((y - np.mean(y)) ** 2)
            r_squared = 1 - (ss_res / ss_tot)

            # ADFæ£€éªŒï¼ˆä½¿ç”¨å¹³æ»‘ä»·æ ¼è®¡ç®—çš„spreadï¼‰
            spread = y - alpha - beta * p1_for_fit.values
            _, pvalue, _, _, _, _ = adfuller(spread, regression="n", autolag='AIC')

            return {
                'alpha': alpha,
                'beta': beta,
                'r_squared': r_squared,
                'pvalue': pvalue
            }
        except:
            return None

    def _plot_analysis(self):
        """ç»˜åˆ¶åˆ†æç»“æœ"""
        if self.analysis_results is None:
            return

        timestamps = self.analysis_results['timestamps']
        current_zscores = self.analysis_results['current_zscores']
        current_spreads = self.analysis_results['current_spreads']
        alphas = self.analysis_results['alphas']
        betas = self.analysis_results['betas']

        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨mplfinanceç»˜åˆ¶èœ¡çƒ›å›¾
        # ä»åŸå§‹æ•°æ®ä¸­æå–å¯¹åº”æ—¶é—´æ®µçš„ä»·æ ¼
        analysis_start_time = timestamps[0]
        analysis_end_time = timestamps[-1]
        # è¿‡æ»¤åŸå§‹æ•°æ®åˆ°åˆ†ææ—¶é—´èŒƒå›´
        price_data = self.data[
            (self.data['timestamp'] >= analysis_start_time) &
            (self.data['timestamp'] <= analysis_end_time)
        ].copy()

        # å‡†å¤‡èœ¡çƒ›å›¾æ•°æ®æ ¼å¼
        ohlc_data1 = price_data[['timestamp', f'{self.coin1}_open', f'{self.coin1}_high',
                                f'{self.coin1}_low', f'{self.coin1}_close', f'{self.coin1}_volume']].copy()
        ohlc_data1.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
        ohlc_data1.set_index('Date', inplace=True)

        ohlc_data2 = price_data[['timestamp', f'{self.coin2}_open', f'{self.coin2}_high',
                                f'{self.coin2}_low', f'{self.coin2}_close', f'{self.coin2}_volume']].copy()
        ohlc_data2.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
        ohlc_data2.set_index('Date', inplace=True)

        # ç»˜åˆ¶èœ¡çƒ›å›¾ - ä¸Šä¸‹ä¸¤ä¸ªå­å›¾
        print("ğŸ“Š æ˜¾ç¤ºèœ¡çƒ›å›¾...")
        # ä½¿ç”¨mplfinanceåˆ›å»ºåŒ…å«ä¸¤ä¸ªå¸ç§çš„ç»„åˆèœ¡çƒ›å›¾
        # ç”±äºmplfinanceå¤–éƒ¨axesçš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨å•ç‹¬çš„å›¾ä½†ç´§å¯†æ’åˆ—

        # ç¬¬ä¸€ä¸ªèœ¡çƒ›å›¾
        mpf.plot(ohlc_data1, type='candle', volume=True, title=f'{self.coin1} Candlestick', style='charles', figsize=(15, 6))

        # ç¬¬äºŒä¸ªèœ¡çƒ›å›¾
        mpf.plot(ohlc_data2, type='candle', volume=True, title=f'{self.coin2} Candlestick', style='charles', figsize=(15, 6))

        # ç¬¬äºŒæ­¥ï¼šåˆ›å»ºåˆ†æå›¾è¡¨
        print("ğŸ“ˆ æ˜¾ç¤ºåˆ†æå›¾è¡¨...")
        _, axes = plt.subplots(4, 1, figsize=(20, 24))

        # ç¬¬ä¸€å›¾ï¼šZ-Scoreæ—¶é—´åºåˆ—ï¼ˆäº¤æ˜“å†³ç­–ä¿¡å·ï¼‰
        axes[0].plot(timestamps, current_zscores, 'b-', alpha=0.8, linewidth=1.0)
        axes[0].axhline(y=0, color='black', linestyle='-', alpha=0.3)
        axes[0].axhline(y=1, color='orange', linestyle='--', alpha=0.7, label=r'Â±1$\sigma$')
        axes[0].axhline(y=-1, color='orange', linestyle='--', alpha=0.7)
        axes[0].axhline(y=2, color='red', linestyle='--', alpha=0.7, label=r'Â±2$\sigma$')
        axes[0].axhline(y=-2, color='red', linestyle='--', alpha=0.7)
        axes[0].axhline(y=3, color='darkred', linestyle=':', alpha=0.7, label=r'Â±3$\sigma$')
        axes[0].axhline(y=-3, color='darkred', linestyle=':', alpha=0.7)
        axes[0].set_ylabel('Current Z-Score')
        axes[0].set_ylim(-5, 5)
        axes[0].set_title(f'{self.coin1}-{self.coin2} Current Z-Score (Trading Decision Signal)')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # ç¬¬äºŒå›¾ï¼šSpreadæ—¶é—´åºåˆ—
        axes[1].plot(timestamps, current_spreads, 'g-', alpha=0.7, linewidth=1.0)
        axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.3)
        axes[1].set_ylabel('Current Spread')
        axes[1].set_title('Current Spread Time Series')
        axes[1].grid(True, alpha=0.3)

        # ç¬¬ä¸‰å›¾ï¼šåŠ¨æ€Alphaå’ŒBetaå‚æ•°
        ax3_alpha = axes[2]
        ax3_beta = ax3_alpha.twinx()
        line1 = ax3_alpha.plot(timestamps, alphas, 'g-', alpha=0.7, linewidth=1.0, label='Alpha')
        line2 = ax3_beta.plot(timestamps, betas, 'r-', alpha=0.7, linewidth=1.0, label='Beta')
        ax3_alpha.set_ylabel('Alpha', color='g')
        ax3_beta.set_ylabel('Beta', color='r')
        ax3_alpha.set_title('Rolling OLS Parameters')
        ax3_alpha.grid(True, alpha=0.3)

        # åˆå¹¶å›¾ä¾‹
        lines = line1 + line2
        labels = [l.get_label() for l in lines]
        ax3_alpha.legend(lines, labels, loc='upper left')

        # ç¬¬å››å›¾ï¼šZ-Scoreåˆ†å¸ƒ
        axes[3].hist(current_zscores, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[3].axvline(x=0, color='black', linestyle='-', alpha=0.5)
        axes[3].axvline(x=1, color='orange', linestyle='--', alpha=0.7)
        axes[3].axvline(x=-1, color='orange', linestyle='--', alpha=0.7)
        axes[3].axvline(x=2, color='red', linestyle='--', alpha=0.7)
        axes[3].axvline(x=-2, color='red', linestyle='--', alpha=0.7)

        axes[3].set_xlabel('Current Z-Score')
        axes[3].set_ylabel('Frequency')
        axes[3].set_title('Current Z-Score Distribution (Trading Decision Basis)')
        axes[3].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

    def _print_summary(self):
        """æ‰“å°åˆ†æç»“æœæ‘˜è¦"""
        if self.analysis_results is None:
            return

        results = self.analysis_results['results']
        current_zscores = self.analysis_results['current_zscores']
        alphas = self.analysis_results['alphas']
        betas = self.analysis_results['betas']

        print(f"\n=== {self.coin1}-{self.coin2} æ»‘åŠ¨çª—å£åˆ†ææ‘˜è¦ ===")
        print(f"åˆ†æå‚æ•°: çª—å£å¤§å°={self.window_size}, æ­¥é•¿={self.step_size}, Z-Scoreå›çœ‹={self.lookback_zscore}")
        if self.ma_window is not None:
            print(f"çª—å£æ•°æ®å¹³æ»‘å‚æ•°: {self.ma_type.upper()} çª—å£={self.ma_window}")
        print(f"å›å½’æ¨¡å‹: {self.reg_method.upper()}")
        print(f"æ€»æ•°æ®ç‚¹: {len(results)}")

        # æ•°æ®æ³„éœ²æ£€æŸ¥
        lookback_counts = [r['lookback_count'] for r in results]
        max_lookback = max(lookback_counts) if lookback_counts else 0
        leakage_check = max_lookback <= self.lookback_zscore
        print(f"\nğŸ”’ æ•°æ®æ³„éœ²æ£€æŸ¥:")
        print(f"æœ€å¤§å†å²çª—å£: {max_lookback}, è®¾å®šä¸Šé™: {self.lookback_zscore}")
        print(f"æ³„éœ²æ£€æŸ¥ç»“æœ: {'âœ… é€šè¿‡' if leakage_check else 'âŒ å¤±è´¥'}")

        # Z-Scoreç»Ÿè®¡
        print(f"\nğŸ“Š Z-Scoreç»Ÿè®¡ (äº¤æ˜“å†³ç­–ä¿¡å·):")
        print(f"èŒƒå›´: {np.min(current_zscores):.2f} è‡³ {np.max(current_zscores):.2f}")
        print(f"å‡å€¼: {np.mean(current_zscores):.3f}, æ ‡å‡†å·®: {np.std(current_zscores):.3f}")
        print(f"|Z|>1 ä¿¡å·æ¯”ä¾‹: {np.mean(np.abs(current_zscores) > 1):.2%}")
        print(f"|Z|>2 å¼ºä¿¡å·æ¯”ä¾‹: {np.mean(np.abs(current_zscores) > 2):.2%}")
        print(f"|Z|>3 æç«¯ä¿¡å·æ¯”ä¾‹: {np.mean(np.abs(current_zscores) > 3):.2%}")

        # å‚æ•°ç¨³å®šæ€§
        alpha_volatility = np.std(alphas)
        beta_volatility = np.std(betas)
        alpha_change = (max(alphas) - min(alphas)) / abs(np.mean(alphas)) * 100
        beta_change = (max(betas) - min(betas)) / abs(np.mean(betas)) * 100

        print(f"\nğŸ›ï¸ å‚æ•°ç¨³å®šæ€§:")
        print(f"Alpha æ³¢åŠ¨ç‡: {alpha_volatility:.6f}, å˜åŒ–å¹…åº¦: {alpha_change:.2f}%")
        print(f"Beta æ³¢åŠ¨ç‡: {beta_volatility:.6f}, å˜åŒ–å¹…åº¦: {beta_change:.2f}%")

        # åæ•´è´¨é‡
        r_squared_values = self.analysis_results['r_squared_values']
        adf_pvalues = self.analysis_results['adf_pvalues']
        adf_pass_rate = np.mean([p < 0.05 for p in adf_pvalues])

        print(f"\nğŸ“ˆ åæ•´è´¨é‡:")
        print(f"å¹³å‡RÂ²: {np.mean(r_squared_values):.4f}")
        print(f"ADFæ£€éªŒé€šè¿‡ç‡: {adf_pass_rate:.2%}")


def main():
    loader = DataLoader()

    # æ»‘åŠ¨çª—å£åˆ†æ - æ”¯æŒMAå¹³æ»‘åŠŸèƒ½
    coin1, coin2 = 'MANA', 'SAND'  # å¯ä»¥ä¿®æ”¹è¿™é‡Œé€‰æ‹©ä¸åŒçš„äº¤æ˜“å¯¹

    print(f"=== æ»‘åŠ¨çª—å£åˆ†æ {coin1}-{coin2} ===")

    # MAå¹³æ»‘å‚æ•°é…ç½®
    ma_window = 3       # None=ä¸å¯ç”¨å¹³æ»‘, æ•´æ•°=å¹³æ»‘çª—å£å¤§å°
    ma_type = 'sma'        # 'sma'=ç®€å•ç§»åŠ¨å¹³å‡, 'ema'=æŒ‡æ•°ç§»åŠ¨å¹³å‡

    # é°æ£’å›å½’å‚æ•°é…ç½®
    reg_method = 'ols'  # None or 'ols'=æ™®é€šOLS, 'huber'=Huberå›å½’

    # ä»·æ ¼å˜æ¢å‚æ•°é…ç½®
    price_transform = 'log'  # 'log'=å¯¹æ•°å˜æ¢, 'raw'=åŸå§‹ä»·æ ¼, 'ratio'=æ¯”ç‡å˜æ¢(åŸºäºçª—å£ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹)

    # åŠ è½½1åˆ†é’Ÿæ•°æ®
    start_date = '2025-08-12'
    data = loader.load_pair_data(coin1, coin2, start_date=start_date)
    print(f'åˆ†ææ—¶é—´è·¨åº¦ï¼Œèµ·å§‹æ—¶é—´{start_date}')
    print(f"\næ•°æ®éªŒè¯:")
    print(f"1mæ•°æ®é•¿åº¦: {len(data)}")

    # åˆ›å»ºåˆ†æå™¨
    rw_analyzer = RollingWindowAnalyzer(
        window_size=100,           # OLSæ‹Ÿåˆçª—å£
        step_size=10,              # å‚æ•°æ›´æ–°é¢‘ç‡
        lookback_zscore=100,       # z-scoreå†å²åŸºå‡†
        ma_window=ma_window,       # MAå¹³æ»‘çª—å£
        ma_type=ma_type,           # MAç±»å‹
        reg_method=reg_method  # é²æ£’å›å½’æ–¹æ³•
    )

    min_required = rw_analyzer.window_size + rw_analyzer.lookback_zscore + rw_analyzer.step_size
    print(f"æœ€å°æ•°æ®éœ€æ±‚: {min_required}æ¡ ({min_required / 1440:.1f}å¤©)")

    print("\nâœ… å¼€å§‹åˆ†æ...")
    print("ğŸ¯ ç›´æ¥è®¡ç®—å½“å‰z-scoreï¼Œæ— é¢„æµ‹å¤æ‚æ€§")
    result = rw_analyzer.analyze_pair(data, coin1, coin2, price_transform=price_transform)
    print("\nğŸ‰ åˆ†æå®Œæˆï¼")

    # åˆ†æç»“æœ
    current_zscores = result['current_zscores']
    alphas = result['alphas']
    betas = result['betas']

    print(f"\nğŸ“Š å½“å‰z-scoreä¿¡å·åˆ†æ:")
    print(f"æ€»ä¿¡å·æ•°: {len(current_zscores)}")
    print(f"ä¿¡å·èŒƒå›´: {np.min(current_zscores):.2f} è‡³ {np.max(current_zscores):.2f}")

    # äº¤æ˜“ä¿¡å·ç»Ÿè®¡
    weak_signals = np.mean(np.abs(current_zscores) > 1)
    medium_signals = np.mean(np.abs(current_zscores) > 2)
    strong_signals = np.mean(np.abs(current_zscores) > 3)

    print(f"\nğŸ¯ äº¤æ˜“ä¿¡å·åˆ†å¸ƒ:")
    print(f"  å¼±ä¿¡å· (|Z|>1): {weak_signals:.1%} - è€ƒè™‘å»ºä»“")
    print(f"  ä¸­ç­‰ä¿¡å· (|Z|>2): {medium_signals:.1%} - å»ºè®®å»ºä»“")
    print(f"  å¼ºä¿¡å· (|Z|>3): {strong_signals:.1%} - å¼ºçƒˆå»ºä»“")

    # å‚æ•°ç¨³å®šæ€§
    alpha_stability = np.std(alphas) / abs(np.mean(alphas)) * 100
    beta_stability = np.std(betas) / abs(np.mean(betas)) * 100

    print(f"\nğŸ›ï¸ å‚æ•°ç¨³å®šæ€§:")
    print(f"Alphaç›¸å¯¹æ³¢åŠ¨: {alpha_stability:.2f}%")
    print(f"Betaç›¸å¯¹æ³¢åŠ¨: {beta_stability:.2f}%")

    # å®é™…äº¤æ˜“å»ºè®®
    print(f"\nğŸ’¡ å®é™…äº¤æ˜“å»ºè®®:")
    if medium_signals > 0.1:
        print("âœ… è¯¥é…å¯¹æœ‰è¶³å¤Ÿçš„ä¸­ç­‰å¼ºåº¦ä¿¡å·ï¼Œé€‚åˆäº¤æ˜“")
        print(f"é¢„æœŸæ¯{len(current_zscores) / medium_signals / len(current_zscores) * 500:.0f}åˆ†é’Ÿæœ‰ä¸€æ¬¡ä¸­ç­‰ä¿¡å·")
    else:
        print("âš ï¸  è¯¥é…å¯¹ä¿¡å·è¾ƒå¼±ï¼Œå¯èƒ½ä¸é€‚åˆå½“å‰å‚æ•°è®¾ç½®")

    if alpha_stability < 5 and beta_stability < 5:
        print("âœ… åæ•´å‚æ•°ç¨³å®šï¼Œå…³ç³»å¯é ")
    else:
        print("âš ï¸  åæ•´å‚æ•°æ³¢åŠ¨è¾ƒå¤§ï¼Œéœ€è¦è°¨æ…äº¤æ˜“")

    print(f"\nğŸ”§ Hummingboté…ç½®å»ºè®®:")
    avg_zscore_std = np.std(current_zscores)
    print(f"entry_threshold: {avg_zscore_std * 1.5:.2f}")
    print(f"lookback_period: {rw_analyzer.window_size}")


if __name__ == "__main__":
    main()

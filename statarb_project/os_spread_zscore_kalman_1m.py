import logging
import warnings
from pathlib import Path

import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from arbitragelab.other_approaches.kalman_filter import KalmanFilterStrategy
from sklearn.linear_model import LinearRegression

logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)

# ç®€å•è®¾ç½®å­—ä½“ï¼Œé¿å…è­¦å‘Š
matplotlib.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')


class DataLoader:

    def __init__(self, data_dir="/Users/zhanghao/GitHub/hummingbot/data/", market="futures", interval="1m"):
        self.interval = interval
        _data_dir = data_dir + f"{market}_{interval}"
        self.data_dir = Path(_data_dir)
        self.pairs = [f.stem.replace(f"_{interval}", "") for f in self.data_dir.glob(f"*_{interval}.csv")]

    def load_pair_data(self, coin1, coin2, start_date=None, end_date=None):
        pair1 = f"{coin1}USDT"
        pair2 = f"{coin2}USDT"

        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        file1 = self.data_dir / f"{pair1}_{self.interval}.csv"
        file2 = self.data_dir / f"{pair2}_{self.interval}.csv"

        missing_files = []
        if not file1.exists():
            missing_files.append(f"{pair1}_{self.interval}.csv")
        if not file2.exists():
            missing_files.append(f"{pair2}_{self.interval}.csv")

        if missing_files:
            return None

        # åŠ è½½æ•°æ®
        df1 = pd.read_csv(file1)
        df2 = pd.read_csv(file2)

        # è½¬æ¢æ—¶é—´æˆ³
        df1['timestamp'] = pd.to_datetime(df1['open_time'], utc=True)
        df2['timestamp'] = pd.to_datetime(df2['open_time'], utc=True)

        # è®¡ç®—å…±åŒæ—¶é—´èŒƒå›´
        common_start = max(df1['timestamp'].min(), df2['timestamp'].min())
        common_end = min(df1['timestamp'].max(), df2['timestamp'].max())

        # ç”¨æˆ·æŒ‡å®šæ—¥æœŸèŒƒå›´
        if start_date:
            start_date_tz = pd.to_datetime(start_date, utc=True)
            common_start = max(common_start, start_date_tz)
        if end_date:
            end_date_tz = pd.to_datetime(end_date, utc=True)
            common_end = min(common_end, end_date_tz)

        # è¿‡æ»¤åˆ°å…±åŒæ—¶é—´èŒƒå›´å¹¶æ’åº
        df1_filtered = df1[(df1['timestamp'] >= common_start) & (df1['timestamp'] <= common_end)].sort_values('timestamp').reset_index(drop=True)
        df2_filtered = df2[(df2['timestamp'] >= common_start) & (df2['timestamp'] <= common_end)].sort_values('timestamp').reset_index(drop=True)

        # æ„å»ºå¯¹é½æ•°æ®
        df1_clean = df1_filtered[['timestamp', 'open', 'high', 'low', 'close', 'volume']].rename(columns={
            'open': f'{coin1}_open', 'high': f'{coin1}_high', 'low': f'{coin1}_low',
            'close': f'{coin1}_close', 'volume': f'{coin1}_volume'
        })
        df2_clean = df2_filtered[['timestamp', 'open', 'high', 'low', 'close', 'volume']].rename(columns={
            'open': f'{coin2}_open', 'high': f'{coin2}_high', 'low': f'{coin2}_low',
            'close': f'{coin2}_close', 'volume': f'{coin2}_volume'
        })

        # å†…è¿æ¥å¾—åˆ°å¯¹é½çš„æ•°æ®
        data = pd.merge(df1_clean, df2_clean, on='timestamp', how='inner').sort_values('timestamp').reset_index(drop=True)

        return data


class KalmanFilterAnalyzer:

    def __init__(
        self, lookback_zscore=1000, kalman_obs_cov=None, kalman_trans_cov=None, delta=1e-2):
        """
        å‚æ•°:
        lookback_zscore: è®¡ç®—z-scoreåŸºå‡†æ—¶ä½¿ç”¨çš„å†å²spreadæ•°é‡
        kalman_obs_cov: float or None, Kalmanæ»¤æ³¢è§‚æµ‹åæ–¹å·®ï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨æ ¡å‡†ï¼‰
        kalman_trans_cov: float or None, Kalmanæ»¤æ³¢è½¬æ¢åæ–¹å·®ï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨æ ¡å‡†ï¼‰
        delta: float, æ§åˆ¶Î²æ¼‚ç§»é€Ÿåº¦çš„å‚æ•°ï¼Œç”¨äºtrans_covæ ¡å‡†
        """
        self.lookback_zscore = lookback_zscore
        self.kalman_obs_cov = kalman_obs_cov
        self.kalman_trans_cov = kalman_trans_cov
        self.delta = delta

        # å­˜å‚¨åˆ†æç»“æœ
        self.analysis_results = None
        self.data = None
        self.coin1 = None
        self.coin2 = None

        # å…¨å±€Kalmanæ»¤æ³¢å™¨
        self.global_kalman_filter = None

    def _calibrate_parameters(self, price1_series, price2_series, n_train):
        """ä½¿ç”¨OLSæ®‹å·®æ ¡å‡†Kalmanå‚æ•°"""
        print(f"ğŸ”§ ä½¿ç”¨{n_train}ä¸ªç‚¹è¿›è¡ŒOLSå‚æ•°ä¼°è®¡")

        X = price1_series.iloc[:n_train].values.reshape(-1, 1)
        y = price2_series.iloc[:n_train].values

        ols = LinearRegression().fit(X, y)
        ols_residuals = y - ols.predict(X)
        ols_variance = np.var(ols_residuals, ddof=1)

        obs_cov = ols_variance
        trans_cov = self.delta * obs_cov / (1 - self.delta)

        return obs_cov, trans_cov

    def analyze_pair(self, data, coin1, coin2, price_transform='log'):
        # å­˜å‚¨æ•°æ®ç”¨äºåç»­åˆ†æ
        self.data = data
        self.coin1 = coin1
        self.coin2 = coin2

        # æå–ä»·æ ¼æ•°æ®ï¼ˆä»…ä½¿ç”¨closeï¼‰
        if price_transform == 'log':
            price1_close = np.log(data[f'{coin1}_close'])
            price2_close = np.log(data[f'{coin2}_close'])
        else:
            price1_close = data[f'{coin1}_close']
            price2_close = data[f'{coin2}_close']

        # å‚æ•°æ ¡å‡†ï¼ˆå¦‚æœéœ€è¦ï¼‰å¹¶ç¡®å®šè®­ç»ƒé›†å¤§å°
        if self.kalman_obs_cov is None or self.kalman_trans_cov is None:
            print("ğŸ”§ æ ¡å‡†Kalmanå‚æ•°...")
            n_train = min(self.lookback_zscore, len(price1_close) // 3)
            obs_cov, trans_cov = self._calibrate_parameters(price1_close, price2_close, n_train)
            print(f"âœ… æ ¡å‡†åå‚æ•°: obs_cov={obs_cov:.6f}, trans_cov={trans_cov:.6f}")
        else:
            obs_cov = self.kalman_obs_cov
            trans_cov = self.kalman_trans_cov
            n_train = 0  # é¢„è®¾å‚æ•°æ—¶æ— è®­ç»ƒé›†
            print(f"ğŸ”„ ä½¿ç”¨é¢„è®¾å‚æ•°: obs_cov={obs_cov}, trans_cov={trans_cov}")

        # åˆå§‹åŒ–å…¨å±€Kalmanæ»¤æ³¢å™¨ï¼ˆä½¿ç”¨æ ¡å‡†æˆ–é¢„è®¾å‚æ•°ï¼‰
        self.global_kalman_filter = KalmanFilterStrategy(
            observation_covariance=obs_cov,
            transition_covariance=trans_cov
        )
        # é™é»˜é¢„çƒ­ï¼Œæ›´æ–°Kalmanæ»¤æ³¢å™¨çŠ¶æ€ï¼Œä½†ä¸äº§ç”Ÿä¿¡å·
        for t in range(1, n_train + 1):
            self.global_kalman_filter.update(price1_close.iloc[t - 1], price2_close.iloc[t - 1])

        results = []

        # ç¡®å®šåˆ†æèµ·å§‹ç‚¹ï¼Œé¿å…é‡å¤ä½¿ç”¨è®­ç»ƒæ•°æ®
        start_idx = max(1, n_train + 1)

        print(f"Kalmanæ»¤æ³¢é€ç‚¹åˆ†æ {coin1}-{coin2}")
        print(f"Z-Scoreå›çœ‹: {self.lookback_zscore}")
        print("âœ… é€»è¾‘: æ¯ä¸ªæ•°æ®ç‚¹å¢é‡æ›´æ–°ï¼Œæ—¶ç‚¹åŒæ­¥ä¿¡å·")

        # é€ç‚¹Kalmanæ»¤æ³¢åˆ†æ
        for i in range(start_idx, len(data)):

            # è·å–å½“å‰æ—¶ç‚¹ä¿¡æ¯
            current_p1 = price1_close.iloc[i]
            current_p2 = price2_close.iloc[i]
            current_timestamp = data['timestamp'].iloc[i]

            # ä½¿ç”¨å½“å‰è§‚æµ‹æ›´æ–°Kalmanæ»¤æ³¢å™¨å¹¶è·å–åŒæ—¶ç‚¹ä¿¡å·
            self.global_kalman_filter.update(current_p1, current_p2)

            # è·å–å½“å‰å‚æ•°ä¼°è®¡
            if len(self.global_kalman_filter.hedge_ratios) > 0:
                current_alpha = self.global_kalman_filter.intercepts[-1]
                current_beta = self.global_kalman_filter.hedge_ratios[-1]

                # ä½¿ç”¨å®˜æ–¹åº“çš„é¢„æµ‹è¯¯å·®å’Œæ ‡å‡†å·®ï¼ˆç»Ÿä¸€ä¿¡å·æºï¼‰
                if len(self.global_kalman_filter.spread_series) > 0:
                    prediction_error = self.global_kalman_filter.spread_series[-1]  # e_t
                    prediction_std = self.global_kalman_filter.spread_std_series[-1]  # sqrt(Q_t)

                    if prediction_std > 0:
                        current_zscore = prediction_error / prediction_std  # å®˜æ–¹æ ‡å‡†åŒ–æ–¹æ³•
                    else:
                        current_zscore = 0.0

                    # è®¡ç®—traditional spreadï¼ˆä»…ç”¨äºå¯è§†åŒ–å¯¹æ¯”ï¼‰
                    current_spread = current_p2 - current_alpha - current_beta * current_p1
                else:
                    continue
            else:
                continue

            # å­˜å‚¨å½“å‰ç‚¹çš„ç»“æœ
            results.append({
                'timestamp': current_timestamp,
                'position': i,
                'alpha': current_alpha,
                'beta': current_beta,
                'current_spread': current_spread,
                'prediction_error': prediction_error,
                'prediction_std': prediction_std,
                'current_zscore': current_zscore,
                'spread_std': prediction_std
            })

        # æ•´ç†åˆ†æç»“æœï¼ˆæ›´æ–°ç»“æ„ï¼‰
        self.analysis_results = {
            'results': results,
            'timestamps': [r['timestamp'] for r in results],
            'current_spreads': [r['current_spread'] for r in results],
            'prediction_errors': [r['prediction_error'] for r in results],
            'prediction_stds': [r['prediction_std'] for r in results],
            'current_zscores': [r['current_zscore'] for r in results],
            'alphas': [r['alpha'] for r in results],
            'betas': [r['beta'] for r in results],
            'spread_stds': [r['spread_std'] for r in results]
        }

        print(f"æˆåŠŸåˆ†æ{len(results)}ä¸ªæ•°æ®ç‚¹")

        # è·å–å®˜æ–¹äº¤æ˜“ä¿¡å·å¹¶è£å‰ªåˆ°ä¸åˆ†æç»“æœåŒ¹é…
        official_signals_full = self.get_official_trading_signals(entry_std=2.0, exit_std=0.0)
        if official_signals_full is not None:
            # è£å‰ªä¿¡å·ä»¥åŒ¹é…åˆ†æç»“æœçš„æ—¶é—´èŒƒå›´(ä»start_idxå¼€å§‹)
            # ç¡®ä¿ä¸è¶…å‡ºå®˜æ–¹ä¿¡å·çš„è¾¹ç•Œ
            available_length = len(official_signals_full['target_quantity']) - start_idx
            actual_length = min(len(results), available_length)
            signal_end_idx = start_idx + actual_length

            self.official_signals = {
                'errors': official_signals_full['errors'].iloc[start_idx:signal_end_idx].reset_index(drop=True),
                'target_quantity': official_signals_full['target_quantity'].iloc[start_idx:signal_end_idx].reset_index(drop=True)
            }
        else:
            self.official_signals = None

        self._plot_analysis()
        self._print_summary()

        return self.analysis_results

    def _plot_analysis(self):
        """ç»˜åˆ¶åˆ†æç»“æœ"""
        if self.analysis_results is None:
            return

        timestamps = self.analysis_results['timestamps']
        current_zscores = self.analysis_results['current_zscores']
        current_spreads = self.analysis_results['current_spreads']
        alphas = self.analysis_results['alphas']
        betas = self.analysis_results['betas']

        # åˆ›å»ºåˆ†æå›¾è¡¨
        _, axes = plt.subplots(5, 1, figsize=(20, 15))

        # ç¬¬ä¸€å›¾ï¼šZ-Scoreæ—¶é—´åºåˆ—ï¼ˆäº¤æ˜“å†³ç­–ä¿¡å·ï¼‰
        axes[0].plot(timestamps, current_zscores, 'b-', alpha=0.8, linewidth=1.0)
        axes[0].axhline(y=0, color='black', linestyle='-', alpha=0.3)
        axes[0].axhline(y=0.5, color='orange', linestyle='--', alpha=0.7, label=r'Â±0.5$\sigma$')
        axes[0].axhline(y=-0.5, color='orange', linestyle='--', alpha=0.7)
        axes[0].axhline(y=1, color='red', linestyle='--', alpha=0.7, label=r'Â±1$\sigma$')
        axes[0].axhline(y=-1, color='red', linestyle='--', alpha=0.7)
        axes[0].axhline(y=1.5, color='darkred', linestyle=':', alpha=0.7, label=r'Â±1.5$\sigma$')
        axes[0].axhline(y=-1.5, color='darkred', linestyle=':', alpha=0.7)
        axes[0].set_ylabel('Current Z-Score')
        axes[0].set_ylim(-3, 3)
        axes[0].set_title(f'{self.coin1}-{self.coin2} Current Z-Score (Trading Decision Signal)')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # ç¬¬äºŒå›¾ï¼šå®˜æ–¹äº¤æ˜“ä¿¡å·
        target_quantity = self.official_signals['target_quantity']

        # ç¡®ä¿æ—¶é—´æˆ³å’Œä¿¡å·é•¿åº¦åŒ¹é…
        min_length = min(len(timestamps), len(target_quantity))
        timestamps_matched = timestamps[:min_length]
        target_quantity_matched = target_quantity[:min_length]

        # ç»˜åˆ¶äº¤æ˜“ä¿¡å·
        axes[1].plot(timestamps_matched, target_quantity_matched, 'purple', alpha=0.8, linewidth=1.5)
        axes[1].fill_between(timestamps_matched, target_quantity_matched, 0,
                             where=(target_quantity_matched > 0), color='green', alpha=0.3, label='Long Signal')
        axes[1].fill_between(timestamps_matched, target_quantity_matched, 0,
                             where=(target_quantity_matched < 0), color='red', alpha=0.3, label='Short Signal')

        axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.5)
        axes[1].axhline(y=1, color='green', linestyle='--', alpha=0.7, label='Long')
        axes[1].axhline(y=-1, color='red', linestyle='--', alpha=0.7, label='Short')
        axes[1].set_ylabel('Trading Signal')
        axes[1].set_title('ArbitrageLab Trading Signal (entry_std=2.0)')
        axes[1].set_ylim(-1.2, 1.2)
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        # ç¬¬ä¸‰å›¾ï¼šSpreadæ—¶é—´åºåˆ—
        axes[2].plot(timestamps, current_spreads, 'g-', alpha=0.7, linewidth=1.0)
        axes[2].axhline(y=0, color='black', linestyle='-', alpha=0.3)
        axes[2].set_ylabel('Current Spread')
        axes[2].set_title('Current Spread Time Series')
        axes[2].grid(True, alpha=0.3)

        # ç¬¬å››å›¾ï¼šåŠ¨æ€Alphaå’ŒBetaå‚æ•°
        ax3_alpha = axes[3]
        ax3_beta = ax3_alpha.twinx()
        line1 = ax3_alpha.plot(timestamps, alphas, 'g-', alpha=0.7, linewidth=1.0, label='Alpha')
        line2 = ax3_beta.plot(timestamps, betas, 'r-', alpha=0.7, linewidth=1.0, label='Beta')
        ax3_alpha.set_ylabel('Alpha', color='g')
        ax3_beta.set_ylabel('Beta', color='r')
        ax3_alpha.set_title('Dynamic Kalman Parameters')
        ax3_alpha.grid(True, alpha=0.3)

        # åˆå¹¶å›¾ä¾‹
        lines = line1 + line2
        labels = [l.get_label() for l in lines]
        ax3_alpha.legend(lines, labels, loc='upper left')

        # ç¬¬äº”å›¾ï¼šZ-Scoreåˆ†å¸ƒ - è¿‡æ»¤NaNå€¼
        zscores_for_hist = np.array(current_zscores)
        zscores_clean = zscores_for_hist[~np.isnan(zscores_for_hist)]
        if len(zscores_clean) > 0:
            axes[4].hist(zscores_clean, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[4].axvline(x=0, color='black', linestyle='-', alpha=0.5)
        axes[4].axvline(x=1, color='orange', linestyle='--', alpha=0.7)
        axes[4].axvline(x=-1, color='orange', linestyle='--', alpha=0.7)
        axes[4].axvline(x=2, color='red', linestyle='--', alpha=0.7)
        axes[4].axvline(x=-2, color='red', linestyle='--', alpha=0.7)

        axes[4].set_xlabel('Current Z-Score')
        axes[4].set_ylabel('Frequency')
        axes[4].set_title('Current Z-Score Distribution (Trading Decision Basis)')
        axes[4].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

    def _print_summary(self):
        """æ‰“å°åˆ†æç»“æœæ‘˜è¦"""
        results = self.analysis_results['results']
        current_zscores = np.array(self.analysis_results['current_zscores'])
        alphas = np.array(self.analysis_results['alphas'])
        betas = np.array(self.analysis_results['betas'])

        # è¿‡æ»¤NaNå€¼
        valid_mask = ~np.isnan(current_zscores)
        current_zscores_clean = current_zscores[valid_mask]
        alphas_clean = alphas[valid_mask]
        betas_clean = betas[valid_mask]

        print(f"\n=== {self.coin1}-{self.coin2} Kalmanæ»¤æ³¢åˆ†ææ‘˜è¦ ===")
        print(f"åˆ†æå‚æ•°: é€ç‚¹æ›´æ–°, Z-Scoreå›çœ‹={self.lookback_zscore}")
        print(f"Kalmanå‚æ•°: obs_cov={self.global_kalman_filter.observation_covariance}, trans_cov={self.global_kalman_filter.transition_covariance}")
        print(f"æ€»æ•°æ®ç‚¹: {len(results)}, æœ‰æ•ˆä¿¡å·ç‚¹: {len(current_zscores_clean)} (è·³è¿‡æš–å¯åŠ¨{self.lookback_zscore}ç‚¹)")

        # Z-Scoreç»Ÿè®¡
        print(f"ğŸ“Š Z-Scoreç»Ÿè®¡ (äº¤æ˜“å†³ç­–ä¿¡å·):")
        print(f"èŒƒå›´: {np.min(current_zscores_clean):.2f} è‡³ {np.max(current_zscores_clean):.2f}")
        print(f"å‡å€¼: {np.mean(current_zscores_clean):.3f}, æ ‡å‡†å·®: {np.std(current_zscores_clean):.3f}")
        print(f"|Z|>0.5 ä¿¡å·æ¯”ä¾‹: {np.mean(np.abs(current_zscores_clean) > 0.5):.2%}")
        print(f"|Z|>1.0 ä¸­ä¿¡å·æ¯”ä¾‹: {np.mean(np.abs(current_zscores_clean) > 1.0):.2%}")
        print(f"|Z|>1.5 å¼ºä¿¡å·æ¯”ä¾‹: {np.mean(np.abs(current_zscores_clean) > 1.5):.2%}")
        print(f"|Z|>2.0 æç«¯ä¿¡å·æ¯”ä¾‹: {np.mean(np.abs(current_zscores_clean) > 2.0):.2%}")

        # å‚æ•°ç¨³å®šæ€§
        alpha_cv = np.std(alphas_clean) / abs(np.mean(alphas_clean)) * 100
        beta_cv = np.std(betas_clean) / abs(np.mean(betas_clean)) * 100
        print(f"ğŸ›ï¸ å‚æ•°ç¨³å®šæ€§:")
        print(f"Alphaå˜å¼‚ç³»æ•°(CV): {alpha_cv:.2f}%")
        print(f"Betaå˜å¼‚ç³»æ•°(CV): {beta_cv:.2f}%")

        # Kalmanæ»¤æ³¢è´¨é‡
        spread_stds = self.analysis_results['spread_stds']
        print(f"ğŸ“ˆ Kalmanæ»¤æ³¢è´¨é‡:")
        print(f"Spreadæ ‡å‡†å·®èŒƒå›´: {np.min(spread_stds):.4f} - {np.max(spread_stds):.4f}")
        print(f"å¹³å‡Spreadæ ‡å‡†å·®: {np.mean(spread_stds):.4f}")

        # äº¤æ˜“ä¿¡å·ç»Ÿè®¡ - ä¿®æ­£ä¿¡å·é¢‘ç‡è®¡ç®—
        weak_signals = np.mean(np.abs(current_zscores_clean) > 0.5)
        medium_signals = np.mean(np.abs(current_zscores_clean) > 1.0)
        strong_signals = np.mean(np.abs(current_zscores_clean) > 1.5)
        extreme_strong_signals = np.mean(np.abs(current_zscores_clean) > 2.0)

        print(f"ğŸ¯ äº¤æ˜“ä¿¡å·åˆ†å¸ƒ:")
        print(f"  å¼±ä¿¡å· (|Z|>0.5): {weak_signals:.1%} - è€ƒè™‘å»ºä»“")
        print(f"  ä¸­ç­‰ä¿¡å· (|Z|>1.0): {medium_signals:.1%} - å»ºè®®å»ºä»“")
        print(f"  å¼ºä¿¡å· (|Z|>1.5): {strong_signals:.1%} - å¼ºçƒˆå»ºä»“")
        print(f"  è¶…å¼ºä¿¡å· (|Z|>2): {extreme_strong_signals:.1%} - å¼ºçƒˆå»ºä»“")
        # ä¿¡å·é¢‘ç‡è®¡ç®—
        if medium_signals > 0:
            print(f"é¢„è®¡æ¯ {1.0 / medium_signals:.1f} åˆ†é’Ÿå‡ºç°ä¸€æ¬¡ä¸­ç­‰ä¿¡å·ï¼ˆâ‰ˆ {1440 * medium_signals:.1f} æ¬¡/æ—¥ï¼‰")
        else:
            print("é¢„è®¡ä¸­ç­‰ä¿¡å·é¢‘ç‡æä½")

        # å®˜æ–¹äº¤æ˜“ä¿¡å·ç»Ÿè®¡
        if hasattr(self, 'official_signals') and self.official_signals is not None:
            print(f"\nğŸ“ˆ ArbitrageLabå®˜æ–¹äº¤æ˜“ä¿¡å·ç»Ÿè®¡:")
            target_quantity = self.official_signals['target_quantity']

            # ä¿¡å·ç»Ÿè®¡
            long_signals = np.sum(target_quantity > 0)
            short_signals = np.sum(target_quantity < 0)
            neutral_signals = np.sum(target_quantity == 0)
            total_signals = len(target_quantity)

            print(f"  æ€»ä¿¡å·æ•°: {total_signals}")
            print(f"  åšå¤šä¿¡å·: {long_signals} ({long_signals / total_signals:.1%})")
            print(f"  åšç©ºä¿¡å·: {short_signals} ({short_signals / total_signals:.1%})")
            print(f"  ä¸­æ€§ä¿¡å·: {neutral_signals} ({neutral_signals / total_signals:.1%})")

            # äº¤æ˜“æ´»è·ƒåº¦
            active_signals = long_signals + short_signals
            if active_signals > 0:
                print(f"  äº¤æ˜“æ´»è·ƒåº¦: {active_signals / total_signals:.1%} (éä¸­æ€§ä¿¡å·æ¯”ä¾‹)")
                print(f"  é¢„è®¡æ¯ {total_signals / active_signals:.1f} åˆ†é’Ÿå‡ºç°äº¤æ˜“ä¿¡å·")
            else:
                print("  äº¤æ˜“æ´»è·ƒåº¦: 0% - æ— äº¤æ˜“ä¿¡å·")

    def get_official_trading_signals(self, entry_std=2.0, exit_std=0.0):
        """
        è·å–ArbitrageLabå®˜æ–¹åº“æ ‡å‡†äº¤æ˜“ä¿¡å·

        :param entry_std: (float) å…¥åœºæ ‡å‡†å·®å€æ•°
        :param exit_std: (float) å‡ºåœºæ ‡å‡†å·®å€æ•°
        :return: (pd.DataFrame) å®˜æ–¹äº¤æ˜“ä¿¡å·DataFrameï¼ŒåŒ…å«errorså’Œtarget_quantity
        """
        return self.global_kalman_filter.trading_signals(entry_std, exit_std)


def main():
    loader = DataLoader()

    # Kalmanæ»¤æ³¢åˆ†æ
    coin1, coin2 = 'MANA', 'SAND'  # å¯ä»¥ä¿®æ”¹è¿™é‡Œé€‰æ‹©ä¸åŒçš„äº¤æ˜“å¯¹

    print(f"=== Kalmanæ»¤æ³¢åˆ†æ {coin1}-{coin2} ===")

    # Kalmanæ»¤æ³¢å‚æ•°é…ç½®
    kalman_obs_cov = None  # 1.0      # è§‚æµ‹åæ–¹å·®
    kalman_trans_cov = None  # 0.001  # è½¬æ¢åæ–¹å·®

    # ä»·æ ¼å˜æ¢å‚æ•°é…ç½®
    price_transform = 'log'  # 'log'=å¯¹æ•°å˜æ¢, å…¶ä»–=åŸå§‹ä»·æ ¼

    # åŠ è½½1åˆ†é’Ÿæ•°æ®
    start_date = '2025-08-10'
    data = loader.load_pair_data(coin1, coin2, start_date=start_date)
    print(f"1mæ•°æ®é•¿åº¦: {len(data)}")

    # åˆ›å»ºåˆ†æå™¨
    kf_analyzer = KalmanFilterAnalyzer(
        lookback_zscore=100,             # z-scoreå†å²åŸºå‡†
        kalman_obs_cov=kalman_obs_cov,   # Kalmanè§‚æµ‹åæ–¹å·®
        kalman_trans_cov=kalman_trans_cov  # Kalmanè½¬æ¢åæ–¹å·®
    )

    print("\nâœ… å¼€å§‹åˆ†æ...")
    _ = kf_analyzer.analyze_pair(data, coin1, coin2, price_transform=price_transform)
    print("ğŸ‰ åˆ†æå®Œæˆï¼")


if __name__ == "__main__":
    main()
